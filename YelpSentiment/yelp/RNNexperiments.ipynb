{"metadata":{"kernel_info":{"name":"Untitled"},"language_info":{"name":"Python","version":"3.7.4-final"},"kernelspec":{"name":"python37464bitbaseconda4ee9745dfb6342f2b1985c4a4af6c263","display_name":"Python 3.7.4 64-bit ('base': conda)"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Using TensorFlow backend.\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"}],"source":["import numpy as np\n","import pandas as pd\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n","from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, LSTM\n","from keras.callbacks import EarlyStopping\n","from keras.preprocessing import text, sequence\n","from nltk.corpus import stopwords\n","import string, nltk, os\n","\n","os.chdir\n","\n","yelp = pd.read_csv('yelp_reviews_sample.csv')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Unnamed: 0               review_id                 user_id  \\\n0           0  Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA   \n1           1  GJXCdrto3ASJOqKeVWPi6Q  yXQM5uF2jS6es16SJzNHfg   \n2           2  2TzJjDVDEuAW6MR5Vuc1ug  n6-Gk65cPZL6Uz8qRm3NYw   \n3           3  yi0R0Ugj_xUx_Nek0-_Qig  dacAIZ6fTM6mqwW5uxkskg   \n4           4  11a8sVPMUFtaC7_ABRkmtw  ssoyf2_x0EQMed6fgHeMyQ   \n\n              business_id  stars  useful  funny  cool  \\\n0  ujmEBvifdJM6h6RLv4wQIg    1.0       6      1     0   \n1  NZnhc2sEQy3RmzKTZnqtwQ    5.0       0      0     0   \n2  WTqjgwHlXbSFevF32_DJVw    5.0       3      0     0   \n3  ikCg8xy5JIg_NGPx-MSIDA    5.0       0      0     0   \n4  b1b1eb3uo-w561D0ZfCEiQ    1.0       7      0     0   \n\n                                                text                 date  \n0  total bill horrible service 8gs crooks actuall...  2013-05-07 04:34:36  \n1  adore travis hard rocks new kelly cardenas sal...  2017-01-14 21:30:33  \n2  say office really together organized friendly ...  2016-11-09 20:09:03  \n3  went lunch steak sandwich delicious caesar sal...  2018-01-09 20:56:38  \n4  today second three sessions paid although firs...  2018-01-30 23:07:38  \n"}],"source":["stop_words = set(stopwords.words('english')) #'if', 'and', 'the', etc.\n","\n","def preprocess(text):\n","    translation = str.maketrans('', '', string.punctuation)\n","    text = text.translate(translation)\n","    text = text.lower()\n","    text = ' '.join(word for word in text.split() if word not in stop_words)\n","    return text\n","\n","yelp['text'] = yelp.apply(lambda row: preprocess(row['text']), axis=1)\n","\n","print(yelp.head())"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"113738\n"}],"source":["No_of_Words = 5000\n","Max_Seq = 200\n","Embed_Dim = 100\n","\n","tokenizer = text.Tokenizer(num_words = No_of_Words, filters = '\"#&()*+,-./;:<=>?@[\\]^_`{|}~', lower=True)\n","tokenizer.fit_on_texts(yelp['text'].values)\n","word_index = tokenizer.word_index\n","\n","print(len(word_index))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(100000, 200)\n"}],"source":["x = tokenizer.texts_to_sequences(yelp['text'].values)\n","x = sequence.pad_sequences(x, maxlen = Max_Seq)\n","\n","print(x.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(100000, 5)\n"}],"source":["y = pd.get_dummies(yelp['stars'].values)\n","\n","print(y.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .2)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWeights successfully loaded.\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nTrain on 64000 samples, validate on 16000 samples\nEpoch 1/1\n64000/64000 [==============================] - 514s 8ms/step - loss: 0.7148 - acc: 0.7024 - val_loss: 0.7013 - val_acc: 0.7041\n\nEpoch 00001: val_loss improved from inf to 0.70135, saving model to weights.hdf5\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 100)    500000      input_1[0][0]                    \n__________________________________________________________________________________________________\nspatial_dropout1d_1 (SpatialDro (None, None, 100)    0           embedding_1[0][0]                \n__________________________________________________________________________________________________\nLSTM_1 (LSTM)                   (None, None, 64)     42240       spatial_dropout1d_1[0][0]        \n__________________________________________________________________________________________________\nglobal_max_pooling1d_1 (GlobalM (None, 64)           0           LSTM_1[0][0]                     \n__________________________________________________________________________________________________\nglobal_average_pooling1d_1 (Glo (None, 64)           0           LSTM_1[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 128)          0           global_max_pooling1d_1[0][0]     \n                                                                 global_average_pooling1d_1[0][0] \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 128)          16512       concatenate_1[0][0]              \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 128)          0           concatenate_1[0][0]              \n                                                                 dense_1[0][0]                    \n__________________________________________________________________________________________________\nsoft_1 (Dense)                  (None, 5)            645         add_1[0][0]                      \n==================================================================================================\nTotal params: 559,397\nTrainable params: 559,397\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n"}],"source":["from keras.callbacks import CSVLogger, ModelCheckpoint\n","\n","words = Input(shape=(None,))\n","x = Embedding(No_of_Words, Embed_Dim)(words)\n","x = SpatialDropout1D(0.2)(x)\n","x = LSTM(64, dropout=0.2, recurrent_dropout=0.2, return_sequences = True, name='LSTM_1')(x)\n","hidden = concatenate([\n","    GlobalMaxPooling1D()(x),\n","    GlobalAveragePooling1D()(x),\n","])\n","hidden = add([hidden, Dense(128)(hidden)])\n","result = Dense(5, activation='softmax', name='soft_1')(hidden)\n","\n","model = Model(words, result)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","try:\n","    model.load_weights('shooting_stars3.h5', by_name = True)\n","    print(\"Weights successfully loaded.\")\n","except:\n","    print(\"No weights loaded. Proceeding to train.\")\n","\n","history = model.fit(x_train, y_train,\n","                    epochs=1,\n","                    batch_size=64,\n","                    validation_split=0.2,\n","                    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001, restore_best_weights=True),\n","                    ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True),\n","                    CSVLogger('log.csv', append=True, separator=';')])\n","\n","model.save_weights('shooting_stars3.h5')\n","model.save('SAmodel.h5')\n","print(model.summary())"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"20000/20000 [==============================] - 48s 2ms/step\nTest set\n Loss: 0.6925991180419921\n Accuracy: 0.70955\n"}],"source":["accuracy = model.evaluate(x_test, y_test)\n","print(f'Test set\\n Loss: {accuracy[0]}\\n Accuracy: {accuracy[1]}')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[0.00225064 0.02780737 0.17857498 0.6430721  0.14829487]]\n4\n"}],"source":["#Making a prediction on a tricky 3-star review from our data.\n","sample = \"Tracy dessert had a big name in Hong Kong and the one in First Markham place has been here for many years now! Came in for some Chinese dessert, and I must say their selection has increased tremendously over the years. I might as well add that the price has also increased tremendously as well. The waitress gave us tea, which I could taste had red date in it. Fancy! A simple taro with coconut with tapioca pearls was like $5.25 or something. Basically all the desserts were more than $5. That's crazy! I can literally just make this dessert at home and for a bowl, it would probably cost like $0.50. A few years ago, I think I can still get it for like $3-$4, which is more reasonable, but wow, more than $5 is a little over the top for this dessert. Though I must say, it is Tracy Dessert, and they are a little more on the expensive side. I also saw other items on the menu like fish balls, chicken wings, shaved ice. My friend got a mango drink with fresh mango in it! I'm also surprised how many people come to Tracy Dessert after work. We came on a Sunday and the tables were always filled. I think the amount of tables they had were just perfect because no one really waited for seats for a long time, but the tables kept filling up once a table was finished.\"\n","sample = preprocess(sample)\n","tokenizer.fit_on_texts(sample)\n","sample = tokenizer.texts_to_sequences([sample])\n","sample = sequence.pad_sequences(sample, maxlen = Max_Seq)\n","\n","pred = model.predict(sample)\n","print(pred)\n","print(np.argmax(pred)+1)\n","#The Sequential class has a predict_classes function, but for the Model class we have to return probability vectors and pick out the highest one."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Very business. Okay. 3 Stars.\n"}],"source":["def predict_review(text):\n","    text = preprocess(text)\n","    tokenizer.fit_on_texts(text)\n","    text = tokenizer.texts_to_sequences([text])\n","    text = sequence.pad_sequences(text, maxlen = Max_Seq)\n","    pred = model.predict(text)\n","    pred = np.argmax(pred)+1\n","    preds = str(pred)\n","    if pred > 3:\n","        print(\"Wow, such service. Great business, \" + preds + \" Stars!\")\n","    elif pred < 3:\n","        print(\"Wow, awful business. Very poor, \" + preds + \" Stars.\")\n","    else:\n","        print(\"Very business. Okay. \" + preds + \" Stars.\")\n","\n","predict_review(input(\"Tell the computer about your experience. \"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}