{"metadata":{"kernel_info":{"name":"Untitled"},"language_info":{"name":"Python","version":"3.7.4-final"},"kernelspec":{"name":"python37464bitbaseconda4ee9745dfb6342f2b1985c4a4af6c263","display_name":"Python 3.7.4 64-bit ('base': conda)"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import nltk\n","#import spacy\n","#nlp = spacy.load('en_core_web_lg')\n","\n","path = r'C:\\Users\\user\\Desktop\\Revature\\Projects\\Yelp\\yelp_reviews_sample.csv'\n","\n","yelpSmall = pd.read_csv(path)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","text_clf = Pipeline([('vect', CountVectorizer()), #This creates vectors\n","                      ('tfidf', TfidfTransformer()), #This calls the TFIDF transformer.\n","                      ('clf', MultinomialNB()),]) #This calls the Naive Bayes algorithm.\n","text_clf = text_clf.fit(yelpSmall['text'], yelpSmall['stars'])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.64646\n"}],"source":["import numpy as np\n","test_data = yelpSmall.sample(frac=1) #A random sample of the dataframe.\n","predicted = text_clf.predict(test_data['text'])\n","print(np.mean(predicted == test_data['stars']))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.51304 0.5390510013777268 0.64646\n"}],"source":["from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score\n","\n","print(mean_absolute_error(test_data['stars'], predicted), r2_score(test_data['stars'], predicted), accuracy_score(test_data['stars'], predicted))"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<blockquote> How come the r2 score is so low, but accuracy is fine and mean absolute error is fine? From the MAE, it looks like we're just one star off from the right answer on average. Double check my code, but I believe the reason for this is that r2 score is meant to show how well we can get a linear prediction from our variables. In short, r2 score isn't meant for classification problems. I found this explanation: https://stats.stackexchange.com/questions/273133/interpretation-of-r-squared-score-of-a-neural-network-for-classification </blockquote>"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[5. 1. 5. 5. 5. 5. 5. 5. 4. 5. 5. 5. 5. 5. 4. 5. 5. 5. 4. 5.] 31610    2.0\n49888    1.0\n78457    1.0\n21593    5.0\n79034    5.0\n24797    5.0\n70057    5.0\n69402    4.0\n9252     3.0\n91822    5.0\n64513    4.0\n32932    3.0\n55230    5.0\n72791    3.0\n46187    4.0\n26327    4.0\n54427    5.0\n63154    3.0\n25613    4.0\n39833    5.0\nName: stars, dtype: float64\n"}],"source":["print(predicted[:20], test_data['stars'].iloc[:20])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#C-type classifier is basically useless. It's way too slow and not good for large datasets.\n","# from sklearn.svm import SVC\n","\n","# text_clf = Pipeline([('vect', CountVectorizer()), #This creates vectors\n","#                       ('tfidf', TfidfTransformer()), #This calls the TFIDF transformer.\n","#                       ('clf', SVC()),]) #This calls the Support Vector classifier algorithm.\n","# text_clf = text_clf.fit(yelpSmall['text'], yelpSmall['stars'])\n","# test_data = yelpSmall.sample(frac=1) #A random sample of the dataframe.\n","# predicted = text_clf.predict(test_data['text'])\n","# print(np.mean(predicted == test_data['stars']))\n","# print(mean_absolute_error(test_data['stars'], predicted), r2_score(test_data['stars'], predicted), accuracy_score(test_data['stars'], predicted))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.67375\n0.46738 0.5858416162407456 0.67375\n"}],"source":["from sklearn.linear_model import SGDClassifier\n","from nltk.corpus import stopwords\n","\n","stop_words = set(stopwords.words('english')) #Stop words didn't help. It may be an issue with the code here.\n","\n","text_clf = Pipeline([('vect', CountVectorizer(stop_words = stop_words)), #This creates vectors\n","                      ('tfidf', TfidfTransformer()), #This calls the TFIDF transformer.\n","                      ('clf', SGDClassifier()),]) #This calls the Support Vector classifier algorithm.\n","text_clf = text_clf.fit(yelpSmall['text'], yelpSmall['stars'])\n","test_data = yelpSmall.sample(frac=1) #A random sample of the dataframe.\n","predicted = text_clf.predict(test_data['text'])\n","print(np.mean(predicted == test_data['stars']))\n","print(mean_absolute_error(test_data['stars'], predicted), r2_score(test_data['stars'], predicted), accuracy_score(test_data['stars'], predicted))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":"\"from sklearn.model_selection import GridSearchCV\\nparameters = {'vect__ngram_range': [(1, 1), (1, 3)],\\n              'vect__lowercase': (True, False),\\n              }\\ngs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\\ngs_clf = gs_clf.fit(yelpSmall['text'], yelpSmall['stars'])\\nprint(gs_clf.best_score_)\\nprint(gs_clf.best_params_)\\nbest_predictions = gs_clf.predict(test_data['text'])\\nprint(mean_absolute_error(test_data['stars'], best_predictions), r2_score(test_data['stars'], best_predictions), accuracy_score(test_data['stars'], best_predictions)) \""},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["'''from sklearn.model_selection import GridSearchCV\n","parameters = {'vect__ngram_range': [(1, 1), (1, 3)],\n","              'vect__lowercase': (True, False),\n","              }\n","gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n","gs_clf = gs_clf.fit(yelpSmall['text'], yelpSmall['stars'])\n","print(gs_clf.best_score_)\n","print(gs_clf.best_params_)\n","best_predictions = gs_clf.predict(test_data['text'])\n","print(mean_absolute_error(test_data['stars'], best_predictions), r2_score(test_data['stars'], best_predictions), accuracy_score(test_data['stars'], best_predictions)) '''\n","#I called GridSearchCV. Sadly, nothing improved.\n","#Lowercase and unigram gave the better results."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.int64'>, encoding='utf-8',\n                input=0     Total bill for this horrible service? Over $8G...\n1     I *adore* Travis at the Hard Rock's new Kelly ...\n2     I have to say that this office really has it t...\n3     Went in for a lunch. Steak sandwich was delici...\n4     Today was my second out of three sessions I ha...\n5     I'll be the first to admit that...\n17    I love chinese food and I love mexican food. W...\n18    We've been a huge Slim's fan since they opened...\n19    Good selection of classes of beers and mains. ...\n20    Our family LOVES the food here. Quick, friendl...\nName: text, dtype: object,\n                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, vocabulary=None)\n"}],"source":["print(CountVectorizer(yelpSmall['text'].loc[:20]))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.68967\n0.43422 0.6257317969926526 0.68967\n"}],"source":["#Due to the possibility of misspellings, I felt it would be worth trying an analyzer that goes by characters. Accuracy improved slightly.\n","text_clf = Pipeline([('vect', CountVectorizer(stop_words = stop_words, analyzer='char_wb', ngram_range=(5,5))), #This creates vectors\n","                      ('tfidf', TfidfTransformer()), #This calls the TFIDF transformer.\n","                      ('clf', SGDClassifier()),]) #This calls the Support Vector classifier algorithm.\n","text_clf = text_clf.fit(yelpSmall['text'], yelpSmall['stars'])\n","test_data = yelpSmall.sample(frac=1) #A random sample of the dataframe.\n","predicted = text_clf.predict(test_data['text'])\n","print(np.mean(predicted == test_data['stars']))\n","print(mean_absolute_error(test_data['stars'], predicted), r2_score(test_data['stars'], predicted), accuracy_score(test_data['stars'], predicted))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}