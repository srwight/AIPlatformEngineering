{"metadata":{"kernel_info":{"name":"Untitled"},"language_info":{"name":"Python","version":"3.7.4-final"},"kernelspec":{"name":"python37464bitbaseconda4ee9745dfb6342f2b1985c4a4af6c263","display_name":"Python 3.7.4 64-bit ('base': conda)"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Unnamed: 0               review_id                 user_id  \\\n0           0  Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA   \n1           1  GJXCdrto3ASJOqKeVWPi6Q  yXQM5uF2jS6es16SJzNHfg   \n2           2  2TzJjDVDEuAW6MR5Vuc1ug  n6-Gk65cPZL6Uz8qRm3NYw   \n3           3  yi0R0Ugj_xUx_Nek0-_Qig  dacAIZ6fTM6mqwW5uxkskg   \n4           4  11a8sVPMUFtaC7_ABRkmtw  ssoyf2_x0EQMed6fgHeMyQ   \n\n              business_id  stars  useful  funny  cool  \\\n0  ujmEBvifdJM6h6RLv4wQIg    1.0       6      1     0   \n1  NZnhc2sEQy3RmzKTZnqtwQ    5.0       0      0     0   \n2  WTqjgwHlXbSFevF32_DJVw    5.0       3      0     0   \n3  ikCg8xy5JIg_NGPx-MSIDA    5.0       0      0     0   \n4  b1b1eb3uo-w561D0ZfCEiQ    1.0       7      0     0   \n\n                                                text                 date  \n0  total bill horrible service 8gs crooks actuall...  2013-05-07 04:34:36  \n1  adore travis hard rocks new kelly cardenas sal...  2017-01-14 21:30:33  \n2  say office really together organized friendly ...  2016-11-09 20:09:03  \n3  went lunch steak sandwich delicious caesar sal...  2018-01-09 20:56:38  \n4  today second three sessions paid although firs...  2018-01-30 23:07:38  \n"}],"source":["from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from nltk.corpus import stopwords\n","import joblib, string, os\n","import numpy as np\n","\n","os.chdir(r'C:\\Users\\user\\Desktop\\Revature\\Projects\\Yelp\\stacked')\n","path = r'C:\\Users\\user\\Desktop\\Revature\\Projects\\Yelp\\yelp_reviews_sample.csv'\n","\n","df = pd.read_csv(path)\n","\n","stop_words = set(stopwords.words('english')) #'if', 'and', 'the', etc.\n","\n","def preprocess(text):\n","    translation = str.maketrans('', '', string.punctuation)\n","    text = text.translate(translation)\n","    text = text.lower()\n","    text = ' '.join(word for word in text.split() if word not in stop_words)\n","    return text\n","\n","df['text'] = df.apply(lambda row: preprocess(row['text']), axis=1)\n","\n","print(df.head())\n","\n","filenames = ['linearSVC.joblib', 'NB_model.joblib', 'SGD_class.joblib']\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["## Loading the models ##\n","linearSVC = joblib.load('linearSVC.joblib')\n","NB_model = joblib.load('NB_model.joblib')\n","SGD_class = joblib.load('SGD_class.joblib')\n","#vectors = joblib.load('vectors.joblib')\n","\n","models = [linearSVC, NB_model, SGD_class]\n","\n","## Vectorizing again - ideally we load the old vectorizer in production ##\n","vectorizer = TfidfVectorizer()\n","vectors = vectorizer.fit_transform(df.text)\n","df_test = vectorizer.transform(df.text)\n","\n","## Doing a train-test split ##\n","x = df.text\n","x = vectorizer.transform(x) #preparing the data\n","y = df.stars\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .2)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n          verbose=0) \n\n0.6409\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n\n0.49595\nSGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False) \n\n0.6295\n"}],"source":["## Testing the models ##\n","for m in models:\n","    m.fit(x_train, y_train)\n","    predictions = m.predict(x_test)\n","    print(m, '\\n')\n","    print(accuracy_score(y_test, predictions))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def stack_predict(models, X):\n","    '''Making predictions with each model.'''\n","    predictions = []\n","    for m in models:\n","        prediction = m.predict(X)\n","        #If there are no predictions yet...\n","        if len(predictions) == 0:\n","            #the predictions is a list of our one set of predictions...\n","            predictions = list(map(lambda p:[p], prediction))\n","        else:\n","            #if there are, then we append to each prediction.\n","            for i in range(len(prediction)):\n","                predictions[i].append(prediction[i])\n","    print(predictions[0:20])\n","    return predictions"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def fit_stack(models, X, Y):\n","    '''Fit - Make predictions based on the other models' predictions.'''\n","    stacked_predictions = stack_predict(models, X)\n","    model = LogisticRegression()\n","    model.fit(stacked_predictions, Y)\n","    return model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def stacked_prediction(models, model, X):\n","    '''Make a prediction with the trained ensemble model.'''\n","    stacked_prediction = stack_predict(models, X)\n","    prediction = model.predict(stacked_prediction)\n","    return prediction"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2.0, 5.0, 5.0], [5.0, 5.0, 5.0], [2.0, 5.0, 5.0], [4.0, 5.0, 5.0], [5.0, 5.0, 5.0], [3.0, 5.0, 1.0], [4.0, 4.0, 4.0], [5.0, 5.0, 5.0], [4.0, 5.0, 5.0], [1.0, 5.0, 1.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0], [4.0, 5.0, 5.0], [5.0, 5.0, 5.0], [4.0, 5.0, 5.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0], [1.0, 1.0, 1.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0]]\nC:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html.\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n[[2.0, 5.0, 1.0], [4.0, 5.0, 5.0], [3.0, 5.0, 4.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0], [1.0, 5.0, 1.0], [5.0, 5.0, 5.0], [1.0, 1.0, 1.0], [5.0, 5.0, 5.0], [4.0, 5.0, 5.0], [5.0, 5.0, 5.0], [1.0, 5.0, 1.0], [5.0, 5.0, 5.0], [4.0, 5.0, 5.0], [5.0, 5.0, 5.0], [2.0, 5.0, 5.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0], [5.0, 5.0, 5.0]]\nStacked accuracy: 0.63415\n"}],"source":["model = fit_stack(models, x_train, y_train)\n","predictions = stacked_prediction(models, model, x_test)\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Stacked accuracy: {accuracy}\")"]}]}